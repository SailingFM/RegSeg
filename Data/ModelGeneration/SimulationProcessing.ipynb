{
 "metadata": {
  "name": "SimulationProcessing"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Testing\n",
      "import numpy as np\n",
      "import nibabel as nib\n",
      "import os"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_path = os.path.abspath( 'Model1' )\n",
      "base_path = os.path.abspath( os.getcwd() )\n",
      "#base_path = os.path.abspath( '.' )\n",
      "msk_fname = os.path.join( model_path, 'signal_mask.nii.gz')\n",
      "b0_fname = os.path.join( model_path, 'signal_b0.nii.gz')\n",
      "signal_fname = os.path.join( model_path, 'signal.nii.gz')\n",
      "signal_nii = nib.load( signal_fname )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = np.loadtxt( os.path.join( model_path, 'gradient_list.txt'), dtype=float )\n",
      "bvecs = np.insert( np.transpose( data[:,0:3] ), 0, 0.0, axis=1 )\n",
      "bvals = np.insert( np.transpose( data[:,3] ), 0, 0.0 )\n",
      "np.savetxt( os.path.join( model_path, 'signal.bvec' ), bvecs )\n",
      "np.savetxt( os.path.join( model_path, 'signal.bval' ), bvals[None] )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nii = nib.load( os.path.join( model_path, 'model.nii.gz') )\n",
      "msk_data = np.sum( nii.get_data(), axis=3, dtype=np.uint8)\n",
      "niiMSK = nib.Nifti1Image( msk_data, signal_nii.get_affine() , signal_nii.get_header() )\n",
      "niiMSK._header['glmin'] = np.min(msk_data)\n",
      "niiMSK._header['glmax'] = np.max(msk_data)\n",
      "niiMSK._header['cal_min'] = 0\n",
      "niiMSK._header['cal_max'] = 1\n",
      "niiMSK.set_data_dtype(np.uint8)\n",
      "nib.save( niiMSK, msk_fname )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "msk_data = nib.load( msk_fname ).get_data()\n",
      "b0_data = np.zeros( msk_data.shape, dtype=float )\n",
      "b0_signal_noise = np.random.normal( 1.0, 0.10, b0_data.shape )\n",
      "b0_bg_noise = np.random.rayleigh( 0.07, b0_data.shape )\n",
      "b0_data[ msk_data>0.5 ] = b0_signal_noise[msk_data>0.5]\n",
      "b0_data[ msk_data<=0.5 ] = b0_bg_noise[msk_data<=0.5]\n",
      "niiB0 = nib.Nifti1Image( b0_data, signal_nii.get_affine() , signal_nii.get_header() )\n",
      "niiB0.set_data_dtype(np.float32)\n",
      "nib.save( niiB0, b0_fname )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def dwifinder( dwipath, ext ):\n",
      "    import os\n",
      "    bname = os.path.splitext( dwipath )\n",
      "    if ( bname[1] == '.gz' ):\n",
      "        bname = os.path.splitext( bname[0] )\n",
      "    return '%s.%s' % ( bname[0], ext )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nipype.interfaces.base as base        # base pipeline interface (e.g. command line execution)\n",
      "import nipype.interfaces.io as nio           # Data i/o\n",
      "import nipype.interfaces.utility as util     # utility\n",
      "import nipype.algorithms.misc as misc\n",
      "import nipype.pipeline.engine as pe          # pypeline engine\n",
      "import nipype.interfaces.fsl as fsl          # fsl\n",
      "import nipype.interfaces.freesurfer as fs    # freesurfer\n",
      "import nipype.interfaces.diffusion_toolkit as dtk\n",
      "import nipype.interfaces.mrtrix as mrtrix   #<---- The important new part!\n",
      "import nipype.interfaces.camino as camino\n",
      "\n",
      "fsl.FSLCommand.set_default_output_type('NIFTI_GZ')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "base_dir = os.path.abspath( base_path )\n",
      "pipeline = pe.Workflow(name=\"Model_Process\", base_dir = base_dir)\n",
      "\n",
      "\n",
      "infosource = pe.Node( interface=util.IdentityInterface( fields=['model_id']), name=\"InfoSource\" )\n",
      "infosource.iterables = ( 'model_id', [ 'Model1' ] )\n",
      "\n",
      "# Set up a node to define all inputs required in the pre-processing workflow\n",
      "datasource = pe.Node( interface=nio.DataGrabber(infields=['model_id'], outfields=['b0', 'dwi', 'mask'] ), name=\"DataReader\")\n",
      "datasource.inputs.template = '*'\n",
      "datasource.inputs.base_directory = base_path\n",
      "datasource.inputs.field_template = dict(b0='%s/signal_b0.nii.gz',\n",
      "                                        dwi='%s/signal.nii.gz',\n",
      "                                        mask='%s/signal_mask.nii.gz')\n",
      "datasource.inputs.template_args = dict(b0=[['model_id']],\n",
      "                                       dwi=[['model_id']],\n",
      "                                        mask=[['model_id']])\n",
      "\n",
      "\n",
      "\n",
      "bdatafind = pe.Node( interface=util.IdentityInterface(fields=['in_file', 'in_bvec', 'in_bval' ]),\n",
      "                    name='bdatafind' )\n",
      "combineB0 = pe.Node( interface=util.Merge(2) , name=\"CombineB0\")\n",
      "insertB0 = pe.Node( interface=fsl.Merge(dimension='t', output_type='NIFTI_GZ'), name=\"InsertB0\" )\n",
      "# mask dwi data\n",
      "fsmask = pe.Node(interface=fs.ApplyMask(), name='MaskRawData' )\n",
      "\n",
      "datasink = pe.Node(nio.DataSink(base_directory=model_path,parameterization=False), name='sinker')\n",
      "datasink.container = 'results'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# compute the diffusion tensor in each voxel\n",
      "#dtifit = pe.Node(interface=dtk.DTIRecon(output_type=\"nii.gz\",ignore_exception=True),name='TensorFitting')\n",
      "dtifit = pe.Node( interface=fsl.DTIFit(output_type='NIFTI_GZ'), name='TensorFitting' )\n",
      "\n",
      "# connect nodes\n",
      "pipeline.connect([\n",
      "                         (infosource, datasource, [( 'model_id', 'model_id' ) ])\n",
      "                        ,(datasource,combineB0, [ ('b0','in1'),('dwi','in2') ] )\n",
      "                        ,(combineB0,insertB0, [( 'out','in_files') ] )\n",
      "                        ,(datasource,fsmask, [('mask','mask_file') ])\n",
      "                        ,(insertB0, fsmask, [( 'merged_file', 'in_file' )] )\n",
      "                        ,(datasource,bdatafind,[ ( ('dwi',dwifinder,'bvec'), 'in_bvec'), ( ('dwi', dwifinder, 'bval') ,'in_bval') ])\n",
      "                        ,(bdatafind,dtifit,[ ('in_bvec','bvecs'), ('in_bval','bvals') ])\n",
      "                        ,(fsmask,dtifit,[ ('out_file','dwi') ])                   # FSL\n",
      "                        ,(datasource,dtifit, [ ('mask','mask') ])                 # FSL\n",
      "                        #,(fsmask,dtifit,[ ('out_file','DWI') ])                    # Diffusion Toolkit\n",
      "                        #,(infosource, datasink, [( 'model_id', 'container' )])\n",
      "                        ,(dtifit,datasink, [( 'FA','@FA'), ('MD','@ADC') ] )\n",
      "                        ,(insertB0,datasink, [( 'merged_file','@dwi_raw' ) ])\n",
      "                      ])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pipeline.run()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h2>FA, MD Parameters</h2>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fa = nib.load( os.path.join( model_path, 'ref_FA.nii.gz') ).get_data().reshape(-1)\n",
      "md = nib.load( os.path.join( model_path, 'ref_MD.nii.gz') ).get_data().reshape(-1)\n",
      "model = nib.load( os.path.join( model_path, 'model.nii.gz') ).get_data().reshape(-1,3)\n",
      "feature = np.rollaxis( np.array([ fa, md ]), 0, 2)\n",
      "feature = [ tuple(row) for row in feature ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(0, np.shape( model )[-1] ):\n",
      "    data = [ fa[model[:,i]>0], md[model[:,i]>0] ]\n",
      "    data = np.rollaxis( np.array(data), 0,2)\n",
      "    #data = np[ tuple(row) for row in data ]\n",
      "    print np.mean( data, 0 )\n",
      "    print np.cov( data.T )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[  7.77335644e-01   6.94673450e-04]\n",
        "[[  4.85065832e-03  -6.89610616e-06]\n",
        " [ -6.89610616e-06   1.02706528e-08]]\n",
        "[ 0.11941234  0.00089523]\n",
        "[[  5.90117156e-04  -1.43226633e-06]\n",
        " [ -1.43226633e-06   1.03718252e-08]]\n",
        "[ 0.10283652  0.00298646]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[[  1.19084185e-03   2.22414814e-07]\n",
        " [  2.22414814e-07   1.56537816e-08]]\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nibabel as nib\n",
      "import numpy as np\n",
      "from tvtk.api import tvtk\n",
      "import os\n",
      "fa = nib.load( os.path.join( os.path.abspath('Model1') , 'dtifit__FA.nii.gz') ).get_data()\n",
      "grid = tvtk.ImageData(spacing=(1,1,1), origin=(0,0,0))\n",
      "grid.point_data.scalars = fa.T.ravel() # It wants fortran order???\n",
      "grid.point_data.scalars.name = 'scalars'\n",
      "grid.dimensions = fa.shape\n",
      "w = tvtk.PolyDataWriter(input=grid, file_name=os.path.join( os.path.abspath('Model1') , 'dtifit__FA.vtk' ) )\n",
      "w.write()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h2>Other DTI fitting methods</h2>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_vox_dims(volume):\n",
      "    import nibabel as nb\n",
      "    if isinstance(volume, list):\n",
      "        volume = volume[0]\n",
      "    nii = nb.load(volume)\n",
      "    hdr = nii.get_header()\n",
      "    voxdims = hdr.get_zooms()\n",
      "    return [float(voxdims[0]), float(voxdims[1]), float(voxdims[2])]\n",
      "\n",
      "def get_data_dims(volume):\n",
      "    import nibabel as nb\n",
      "    if isinstance(volume, list):\n",
      "        volume = volume[0]\n",
      "    nii = nb.load(volume)\n",
      "    hdr = nii.get_header()\n",
      "    datadims = hdr.get_data_shape()\n",
      "    return [int(datadims[0]), int(datadims[1]), int(datadims[2])]\n",
      "\n",
      "def get_affine(volume):\n",
      "    import nibabel as nb\n",
      "    nii = nb.load(volume)\n",
      "    return nii.get_affine()\n",
      "\n",
      "# compute the diffusion tensor in each voxel\n",
      "image2voxel = pe.Node(interface=camino.Image2Voxel(out_type='double'), name=\"image2voxel\")\n",
      "fsl2scheme = pe.Node(interface=camino.FSL2Scheme(), name=\"fsl2scheme\")\n",
      "fsl2scheme.inputs.usegradmod = True\n",
      "dtifit = pe.Node(interface=camino.DTIFit(),name='TensorFitting')\n",
      "dtlutgen = pe.Node(interface=camino.DTLUTGen(), name=\"dtlutgen\")\n",
      "dtlutgen.inputs.snr = 16.0\n",
      "dtlutgen.inputs.inversion = 1\n",
      "\n",
      "fa = pe.Node(interface=camino.ComputeFractionalAnisotropy(),name='fa')\n",
      "analyzeheader_fa = pe.Node(interface= camino.AnalyzeHeader(), name = \"analyzeheader_fa\")\n",
      "analyzeheader_fa.inputs.datatype = \"double\"\n",
      "analyzeheader_trace = analyzeheader_fa.clone('analyzeheader_trace')\n",
      "fa2nii = pe.Node(interface=misc.CreateNifti(),name='fa2nii')\n",
      "\n",
      "# connect nodes\n",
      "pipeline.connect([\n",
      "                         (infosource, datasource, [( 'model_id', 'model_id' ) ])\n",
      "                        ,(datasource,combineB0, [ ('b0','in1'),('dwi','in2') ] )\n",
      "                        ,(combineB0,insertB0, [( 'out','in_files') ] )\n",
      "                        ,(datasource,fsmask, [('mask','mask_file') ])\n",
      "                        ,(insertB0, fsmask, [( 'merged_file', 'in_file' )] )\n",
      "                        ,(datasource,bdatafind,[ ( ('dwi',dwifinder,'bvec'), 'in_bvec'), ( ('dwi', dwifinder, 'bval') ,'in_bval') ])\n",
      "                        \n",
      "                        ,(fsmask, image2voxel, [('out_file', 'in_file')])\n",
      "                        ,(bdatafind, fsl2scheme, [('in_bvec', 'bvec_file'), ('in_bval', 'bval_file')])\n",
      "                        ,(image2voxel, dtifit,[['voxel_order','in_file']])\n",
      "                        ,(fsl2scheme, dtifit,[['scheme','scheme_file']])\n",
      "                        ,(dtifit, fa,[(\"tensor_fitted\",\"in_file\")])\n",
      "                        ,(fa, analyzeheader_fa,[(\"fa\",\"in_file\")])\n",
      "                        ,(fsmask, analyzeheader_fa,[(('out_file', get_vox_dims), 'voxel_dims'),(('out_file', get_data_dims), 'data_dims')])\n",
      "                        ,(fa, fa2nii,[('fa','data_file')])\n",
      "                        ,(fsmask, fa2nii,[(('out_file', get_affine), 'affine')])\n",
      "                        ,(analyzeheader_fa, fa2nii,[('header', 'header_file')])\n",
      "                        \n",
      "                        #,(infosource, datasink, [( 'model_id', 'container' )])\n",
      "                        ,(fa2nii,datasink, [( 'nifti_file','@FA') ] )\n",
      "                        ,(fsmask,datasink, [( 'out_file','@dwi_raw' ) ])\n",
      "                      ])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pipeline.run()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mrtrix = pe.Workflow( name=\"MRTrix\" )\n",
      "\n",
      "inputnode = pe.Node( interface=util.IdentityInterface(fields=['DWI', 'bvecs', 'bvals' ]),\n",
      "                    name='inputnode' )\n",
      "outputnode = pe.Node( interface=util.IdentityInterface(fields=['FA', 'ADC']),\n",
      "                    name='outputnode' )\n",
      "#gunzip = pe.Node(interface=misc.Gunzip(), name='gunzip')\n",
      "fsl2mrtrix = pe.Node(interface=mrtrix.FSL2MRTrix(),name='fsl2mrtrix')\n",
      "dwi2tensor = pe.Node(interface=mrtrix.DWI2Tensor(),name='dwi2tensor')\n",
      "tensor2vector = pe.Node(interface=mrtrix.Tensor2Vector(),name='tensor2vector')\n",
      "tensor2adc = pe.Node(interface=mrtrix.Tensor2ApparentDiffusion(),name='tensor2adc')\n",
      "tensor2fa = pe.Node(interface=mrtrix.Tensor2FractionalAnisotropy(),name='tensor2fa')\n",
      "\n",
      "mrtrix.connect([\n",
      "                 (inputnode, dwi2tensor, [ ('DWI', 'in_file') ])\n",
      "                ,(inputnode, fsl2mrtrix, [ ('bvecs','bvec_file'),('bvals','bval_file')])\n",
      "                ,(fsl2mrtrix,dwi2tensor, [ (\"encoding_file\",\"encoding_file\") ] )\n",
      "                ,(dwi2tensor,tensor2vector, [ ('tensor','in_file') ] )\n",
      "                ,(dwi2tensor, tensor2adc,[ ('tensor','in_file') ] )\n",
      "                ,(dwi2tensor, tensor2fa, [ ('tensor','in_file') ] )\n",
      "                ,(tensor2fa, outputnode, [ ('FA','FA' ) ] )\n",
      "                ,(tensor2adc,outputnode, [ ('ADC', 'ADC' ) ])\n",
      "                ])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}