{
 "metadata": {
  "name": "SimulationProcessing"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Testing\n",
      "import numpy as np\n",
      "import nibabel as nib\n",
      "import os"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_path = 'Model1'\n",
      "base_path = os.path.abspath( os.getcwd() )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = np.loadtxt( os.path.join( model_path, 'gradient_list.txt'), dtype=float )\n",
      "bvecs = np.insert( np.transpose( data[:,0:3] ), 0, 0.0, axis=1 )\n",
      "bvals = np.insert( np.transpose( data[:,3] ), 0, 0.0 )\n",
      "np.savetxt( os.path.join( model_path, 'signal.bvec' ), bvecs )\n",
      "np.savetxt( os.path.join( model_path, 'signal.bval' ), bvals[None] )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 90
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nii = nib.load( os.path.join( model_path, 'model.nii.gz') )\n",
      "b0_data = np.sum( nii.get_data(), axis=3, dtype=float)\n",
      "niiHS = nib.Nifti1Image( b0_data, None, None )\n",
      "nib.save( niiHS, os.path.join( model_path, 'signal_mask.nii.gz') )\n",
      "\n",
      "b0_signal_noise = np.random.normal( 1.0, 0.15, b0_data.shape )\n",
      "b0_bg_noise = np.random.rayleigh( 0.07, b0_data.shape )\n",
      "b0_data[ b0_data == 1 ] = b0_signal_noise[b0_data==1]\n",
      "b0_data[ b0_data == 0 ] = b0_bg_noise[b0_data==0]\n",
      "niiHS = nib.Nifti1Image( b0_data, None, None )\n",
      "nib.save( niiHS, os.path.join( model_path, 'signal_b0.nii.gz') )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 91
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def dwifinder( dwipath, ext ):\n",
      "    import os\n",
      "    bname = os.path.splitext( dwipath )\n",
      "    if ( bname[1] == '.gz' ):\n",
      "        bname = os.path.splitext( bname[0] )\n",
      "    return '%s.%s' % ( bname[0], ext )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 92
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nipype.interfaces.base as base        # base pipeline interface (e.g. command line execution)\n",
      "import nipype.interfaces.io as nio           # Data i/o\n",
      "import nipype.interfaces.utility as util     # utility\n",
      "import nipype.algorithms.misc as alg         # Dice, jaccard, haussdorf distances\n",
      "import nipype.pipeline.engine as pe          # pypeline engine\n",
      "import nipype.interfaces.fsl as fsl          # fsl\n",
      "import nipype.interfaces.freesurfer as fs    # freesurfer\n",
      "import nipype.interfaces.diffusion_toolkit as dtk\n",
      "\n",
      "base_dir = os.path.abspath( model_path )\n",
      "pipeline = pe.Workflow(name=\"Model_Process\")\n",
      "\n",
      "\n",
      "infosource = pe.Node( interface=util.IdentityInterface( fields=['model_id']), name=\"InfoSource\" )\n",
      "infosource.iterables = ( 'model_id', [ 1 ] )\n",
      "infosource.base_directory= base_path\n",
      "\n",
      "# Set up a node to define all inputs required in the pre-processing workflow\n",
      "datasource = pe.Node( interface=nio.DataGrabber(infields=['model_id'], outfields=['b0', 'dwi', 'mask'] ), name=\"DataReader\")\n",
      "datasource.inputs.template = '*'\n",
      "datasource.inputs.base_directory = base_path\n",
      "datasource.inputs.field_template = dict(b0='Model%1d/signal_b0.nii.gz',\n",
      "                                        dwi='Model%1d/signal.nii',\n",
      "                                        mask='Model%1d/signal_mask.nii.gz')\n",
      "datasource.inputs.template_args = dict(b0=[['model_id']],\n",
      "                                       dwi=[['model_id']],\n",
      "                                        mask=[['model_id']])\n",
      "\n",
      "\n",
      "\n",
      "bdatafind = pe.Node( interface=util.IdentityInterface(fields=['in_file', 'in_bvec', 'in_bval' ]),\n",
      "                    name='bdatafind' )\n",
      "combineB0 = pe.Node( interface=util.Merge(2) , name=\"CombineB0\")\n",
      "insertB0 = pe.Node( interface=fsl.Merge(dimension='t', output_type='NIFTI_GZ'), name=\"InsertB0\" )\n",
      "# mask dwi data\n",
      "fsmask = pe.Node(interface=fs.ApplyMask(), name='MaskRawData' )\n",
      "# compute the diffusion tensor in each voxel\n",
      "dtifit = pe.Node(interface=dtk.DTIRecon(),name='TensorFitting')\n",
      "\n",
      "combine = pe.Node( interface=util.Merge(2) , name=\"CombineMaps\")\n",
      "# Create an output node to gather all the outputs\n",
      "fslmerge = pe.Node(interface =fsl.Merge(dimension='t',output_type='NIFTI_GZ'), name=\"FSLMerge\" ) \n",
      "datasink = pe.Node(nio.DataSink(base_directory=base_dir), name='sinker')\n",
      "# connect nodes\n",
      "pipeline.connect([\n",
      "                         (infosource, datasource, [( 'model_id', 'model_id' ) ])\n",
      "                        ,(datasource,combineB0, [ ('b0','in1'),('dwi','in2') ] )\n",
      "                        ,(combineB0,insertB0, [( 'out','in_files') ] )\n",
      "                        ,(datasource,fsmask, [('mask','mask_file') ])\n",
      "                        ,(insertB0, fsmask, [( 'merged_file', 'in_file' )] )\n",
      "                        ,(datasource,bdatafind,[ ( ('dwi',dwifinder,'bvec'), 'in_bvec'), ( ('dwi', dwifinder, 'bval') ,'in_bval') ])\n",
      "                        ,(bdatafind,dtifit,[ ('in_bvec','bvecs'), ('in_bval','bvals') ])\n",
      "                        ,(fsmask,dtifit,[ ('out_file','DWI') ]) # Diffusion Toolkit\n",
      "                        ,(dtifit,combine, [ ('FA','in1'),('ADC','in2') ])\n",
      "                        ,(combine,fslmerge, [( 'out','in_files') ] )\n",
      "                        ,(fslmerge,datasink, [( 'merged_file','.@dti_maps') ] )\n",
      "                      ])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/nipype/interfaces/fsl/base.py:116: UserWarning: FSL environment variables not set. setting output type to NIFTI\n",
        "  warnings.warn('FSL environment variables not set. setting output type to NIFTI')\n",
        "/usr/local/lib/python2.7/dist-packages/nipype/interfaces/fsl/base.py:116: UserWarning: FSL environment variables not set. setting output type to NIFTI\n",
        "  warnings.warn('FSL environment variables not set. setting output type to NIFTI')\n"
       ]
      }
     ],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pipeline.write_graph()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "121107-13:32:08,243 workflow INFO:\n",
        "\t Converting dotfile: /home/oesteban/workspace/ACWE-Reg/Data/ModelGeneration/graph.dot to png format\n"
       ]
      }
     ],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pipeline.run()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "121107-13:32:08,517 workflow INFO:\n",
        "\t ['check', 'execution', 'logging']\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "121107-13:32:08,730 workflow INFO:\n",
        "\t Running serially.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "121107-13:32:08,732 workflow INFO:\n",
        "\t Executing node DataReader.a0 in dir: /tmp/tmp10QoiA/Model_Process/_model_id_1/DataReader\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "121107-13:32:08,750 workflow INFO:\n",
        "\t Executing node CombineB0.a0 in dir: /tmp/tmpI25bcf/Model_Process/_model_id_1/CombineB0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "121107-13:32:08,765 workflow INFO:\n",
        "\t Executing node InsertB0.a0 in dir: /tmp/tmpnE1PpM/Model_Process/_model_id_1/InsertB0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "121107-13:32:08,774 workflow INFO:\n",
        "\t Running: fslmerge -t /tmp/tmpnE1PpM/Model_Process/_model_id_1/InsertB0/signal_b0_merged.nii.gz /home/oesteban/workspace/ACWE-Reg/Data/ModelGeneration/Model1/signal_b0.nii.gz /home/oesteban/workspace/ACWE-Reg/Data/ModelGeneration/Model1/signal.nii\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "121107-13:32:45,724 workflow INFO:\n",
        "\t Executing node MaskRawData.a0 in dir: /tmp/tmpdRlnOm/Model_Process/_model_id_1/MaskRawData\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "121107-13:32:45,775 workflow INFO:\n",
        "\t Running: mri_mask /tmp/tmpnE1PpM/Model_Process/_model_id_1/InsertB0/signal_b0_merged.nii.gz /home/oesteban/workspace/ACWE-Reg/Data/ModelGeneration/Model1/signal_mask.nii.gz /tmp/tmpdRlnOm/Model_Process/_model_id_1/MaskRawData/signal_b0_merged_masked.nii.gz\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "121107-13:32:45,836 workflow ERROR:\n",
        "\t ['Node MaskRawData.a0 failed to run on host zeppelin-II.']\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "121107-13:32:45,882 workflow INFO:\n",
        "\t Saving crash info to /home/oesteban/workspace/ACWE-Reg/Data/ModelGeneration/crash-20121107-133245-oesteban-MaskRawData.a0.npz\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "121107-13:32:45,883 workflow INFO:\n",
        "\t Traceback (most recent call last):\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/nipype/pipeline/plugins/linear.py\", line 37, in run\n",
        "    node.run(updatehash=updatehash)\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/nipype/pipeline/engine.py\", line 1128, in run\n",
        "    self._run_interface()\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/nipype/pipeline/engine.py\", line 1226, in _run_interface\n",
        "    self._result = self._run_command(execute)\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/nipype/pipeline/engine.py\", line 1350, in _run_command\n",
        "    result = self._interface.run()\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/nipype/interfaces/freesurfer/base.py\", line 121, in run\n",
        "    return super(FSCommand, self).run(**inputs)\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/nipype/interfaces/base.py\", line 820, in run\n",
        "    runtime = self._run_interface(runtime)\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/nipype/interfaces/base.py\", line 1097, in _run_interface\n",
        "    runtime.hostname))\n",
        "IOError: mri_mask could not be found on host zeppelin-II\n",
        "Interface ApplyMask failed to run. \n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "121107-13:32:45,930 workflow INFO:\n",
        "\t ***********************************\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "121107-13:32:45,930 workflow ERROR:\n",
        "\t could not run node: Model_Process.MaskRawData.a0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "121107-13:32:45,931 workflow INFO:\n",
        "\t crashfile: /home/oesteban/workspace/ACWE-Reg/Data/ModelGeneration/crash-20121107-133245-oesteban-MaskRawData.a0.npz\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "121107-13:32:45,931 workflow INFO:\n",
        "\t ***********************************\n"
       ]
      },
      {
       "ename": "RuntimeError",
       "evalue": "Workflow did not execute cleanly. Check log for details",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-104-45328862925b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/nipype/pipeline/engine.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, plugin, plugin_args, updatehash)\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstr2bool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'execution'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'create_report'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_write_report_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m         \u001b[0mrunner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexecgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdatehash\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdatehash\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mexecgraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/nipype/pipeline/plugins/linear.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, graph, config, updatehash)\u001b[0m\n\u001b[0;32m     53\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_callback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_callback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'exception'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0mreport_nodes_not_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnotrun\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/nipype/pipeline/plugins/base.pyc\u001b[0m in \u001b[0;36mreport_nodes_not_run\u001b[1;34m(notrun)\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"***********************************\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m         raise RuntimeError(('Workflow did not execute cleanly. '\n\u001b[0m\u001b[0;32m     90\u001b[0m                             'Check log for details'))\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mRuntimeError\u001b[0m: Workflow did not execute cleanly. Check log for details"
       ]
      }
     ],
     "prompt_number": 104
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}